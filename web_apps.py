# -*- coding: utf-8 -*-
"""Web Apps.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KSoN3oZxD9PxZgjktULRLbadeOqsrvOT

# Install Packages

Before running the script, you need to upload 2 files:
*   kmeans_model.pkl (this is a trained and exported K-Means model for use to do an unsupervised prediction)
*   preprocessing.py (this script contains the functions neccessary for data preprocessing before further processing by the model)
"""

# !pip install streamlit

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import streamlit as st
import joblib
import pandas as pd
from typing import List
from preprocessing import label_encode_position, validate_data, detect_limit_age, detect_limit_age_tenure, detect_limit_tenure, detect_limit_training_hours, delete_null_rows, fix_col, fix_age, fix_col_level, feat_engineer, feat_normal, feat_encode, feat_scaling, feat_select

model = joblib.load("kmeans_model.pkl")

# Allows disabling button so that users cannot skip steps
if "file_uploaded" not in st.session_state:
    st.session_state.file_uploaded = False

if "data_cleaned" not in st.session_state:
    st.session_state.data_cleaned = False

if "data_predicted" not in st.session_state:
    st.session_state.data_predicted = False

"""# File Upload"""

# Allows user to upload a file
uploaded_file = st.file_uploader(
    "Upload a CSV file",
    type=["csv"]
)

"""## Check Uploaded File"""

# Preview the file
if uploaded_file is not None:
  st.write("Filename:", uploaded_file.name)

  df = pd.read_csv(uploaded_file)
  st.write("Raw Data Preview", df.head())

  # Summons a function to check if file contains any invalid/missing value
  errors = validate_data(df)

  if errors:
      st.session_state["is_valid"] = False
      st.session_state["validation_errors"] = errors
  else:
      st.session_state["is_valid"] = True
      st.session_state["validation_errors"] = []

# If file is found to have invalid/missing value, notify users
if "validation_errors" in st.session_state:
    if st.session_state["validation_errors"]:
        st.session_state.file_uploaded = False
        st.error("❌ Data validation failed:")
        for err in st.session_state["validation_errors"]:
            st.write(f"- {err}")
    else:
        st.success("✅ Data is valid. You may proceed.")
        st.session_state.file_uploaded = True

"""# Data Preprocessing"""

# Clean the data and preview it
if st.button("Clean Data", disabled=not st.session_state.file_uploaded):
    cleaned_df = label_encode_position(df)

    cleaned_df = detect_limit_age(cleaned_df)
    cleaned_df = detect_limit_age_tenure(cleaned_df)
    cleaned_df = detect_limit_tenure(cleaned_df)
    cleaned_df = detect_limit_training_hours(cleaned_df)
    cleaned_df = delete_null_rows(cleaned_df)
    cleaned_df = fix_age(cleaned_df)

    cleaned_df = fix_col(cleaned_df, "Years_at_Company")
    cleaned_df = fix_col(cleaned_df, "Performance_Score")
    cleaned_df = fix_col(cleaned_df, "Leadership_Score")
    cleaned_df = fix_col(cleaned_df, "Training_Hours")
    cleaned_df = fix_col(cleaned_df, "Projects_Handled")
    cleaned_df = fix_col(cleaned_df, "Peer_Review_Score")

    cleaned_df = fix_col_level(cleaned_df)
    cleaned_df = feat_engineer(cleaned_df)
    cleaned_df = feat_normal(cleaned_df)
    cleaned_df = feat_encode(cleaned_df)
    cleaned_df = feat_scaling(cleaned_df)
    st.session_state.cleaned_df = feat_select(cleaned_df, ['Promotion_Eligible', 'Age_log', 'Years_at_Company_log', 'Performance_Score_log',
                                                           'Leadership_Score_log', 'Training_Hours_log', 'Projects_Handled_log', 'Peer_Review_Score_log',
                                                           'Position_Encoded', 'Avg_Score'])


    st.session_state.data_cleaned = True

# Prevent preview of clean data from disappearing when user interacts with the app
if "cleaned_df" in st.session_state:
    st.write("Cleaned Data Preview", st.session_state.cleaned_df.head())

"""# Prediction"""

if st.button("Run Prediction", disabled=not st.session_state.data_cleaned):
    FEATURES = [
        'Age_scaled',
        'Years_at_Company_scaled',
        'Performance_Score_scaled',
        'Leadership_Score_scaled',
        'Training_Hours_scaled',
        'Projects_Handled_scaled',
        'Peer_Review_Score_scaled'
    ]

    X = st.session_state.cleaned_df[FEATURES]
    labels = model.predict(X)

    df["cluster"] = labels

    pca = PCA(n_components=2)
    X_2d = pca.fit_transform(X)

    fig, ax = plt.subplots(figsize=(7, 5))

    scatter = ax.scatter(
        X_2d[:, 0],
        X_2d[:, 1],
        c=labels,
        s=30
    )

    ax.set_xlabel("PCA 1")
    ax.set_ylabel("PCA 2")
    ax.set_title("KMeans Clusters (Inference Only)")

    st.pyplot(fig)

    st.write("Predicted Data Preview", df.head())

    st.session_state["predicted_df"] = df
    st.session_state.data_predicted = True

    # st.subheader("Prediction Scatter Plot")

    # fig, ax = plt.subplots()
    # ax.scatter(df.iloc[:, 0], df["prediction"])
    # ax.set_xlabel("Feature 1")
    # ax.set_ylabel("Prediction")

    # st.pyplot(fig)

"""# Download Output"""

if st.session_state.data_predicted:
    st.download_button(
        label="Download Output",
        data=st.session_state["predicted_df"].to_csv(index=False),
        file_name="model_output.csv",
        mime="text/csv"
    )